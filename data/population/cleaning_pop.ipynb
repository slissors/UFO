{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53 entries, 0 to 52\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   NAME              53 non-null     object\n",
      " 1   POPESTIMATE2009   53 non-null     int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 980.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "pop2009 = pd.read_csv(\"POP2009.csv\")\n",
    "\n",
    "columns_to_keep1 = [\"name\", \"popestimate2009\"]\n",
    "pop2009 = pop2009[columns_to_keep1]\n",
    "\n",
    "# Define a dictionary to map old column names to new ones\n",
    "column_renamed = {\n",
    "    'NAME': 'name',\n",
    "    'POPESTIMATE2009 ' : 'popestimate2009',\n",
    "}\n",
    "\n",
    "# Rename the columns using the mapping\n",
    "pop2009.rename(columns=column_renamed, inplace=True)\n",
    "\n",
    "# Save the DataFrame with the new column names to a new CSV file\n",
    "pop2009.to_csv('POP2009.csv', index=False)\n",
    "\n",
    "pop2009.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57 entries, 0 to 56\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   NAME             57 non-null     object\n",
      " 1   POPESTIMATE2010  57 non-null     int64 \n",
      " 2   POPESTIMATE2011  57 non-null     int64 \n",
      " 3   POPESTIMATE2012  57 non-null     int64 \n",
      " 4   POPESTIMATE2013  57 non-null     int64 \n",
      " 5   POPESTIMATE2014  57 non-null     int64 \n",
      " 6   POPESTIMATE2015  57 non-null     int64 \n",
      " 7   POPESTIMATE2016  57 non-null     int64 \n",
      " 8   POPESTIMATE2017  57 non-null     int64 \n",
      " 9   POPESTIMATE2018  57 non-null     int64 \n",
      " 10  POPESTIMATE2019  57 non-null     int64 \n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 5.0+ KB\n"
     ]
    }
   ],
   "source": [
    "pop2020 = pd.read_csv(\"POP2010-2020.csv\")\n",
    "\n",
    "# Assuming nuforc is a Pandas DataFrame\n",
    "columns_to_delete = [\"SUMLEV\", \"REGION\", \"DIVISION\", \"STATE\", \"CENSUS2010POP\", \"ESTIMATESBASE2010\", \"POPESTIMATE042020\", \"POPESTIMATE2020\" ]\n",
    "pop2020 = pop2020.drop(columns=columns_to_delete)\n",
    "pop2020.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop2022 = pd.read_csv(\"POP2020-2022.csv\")\n",
    "\n",
    "# Too many columns to delete, choosing a function that keeps certain columns instead\n",
    "columns_to_keep2 = [\"NAME\", \"POPESTIMATE2020\", \"POPESTIMATE2021\", \"POPESTIMATE2022\"]\n",
    "pop2022 = pop2022[columns_to_keep2]\n",
    "\n",
    "merged_pop = pd.merge(pop2009, pop2020, on=\"NAME\")\n",
    "merged_pop = pd.merge(merged_pop, pop2022, on=\"NAME\")\n",
    "\n",
    "# Rename the columns\n",
    "for column in merged_pop.columns:\n",
    "    merged_pop.rename(columns={column: column.strip().replace('POPESTIMATE', '')}, inplace=True)\n",
    "\n",
    "\n",
    "merged_pop.to_csv('POP2009-2022.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a CVS file with columns containing NAME (of state), UFO sightings(2009-2022)\n",
    "ufo_data_path = \"../nuforc_reports.csv\"\n",
    "udf = pd.read_csv(ufo_data_path)\n",
    "\n",
    "#Filter rows where the \"country\" column is equal to \"USA\" and keep only necessary coloumns\n",
    "udf = udf[udf['country'] == 'USA']\n",
    "udf = udf[[\"state\", \"country\", \"date\"]]\n",
    "\n",
    "# Convert the \"date_time\" column to datetime and extract year\n",
    "udf['date'] = pd.to_datetime(udf['date'])\n",
    "udf['year'] = udf['date'].dt.year\n",
    "\n",
    "# Filter the DataFrame to include only the years between 2000 and 2010\n",
    "udf_filtered = udf[ (udf['year'] >= 2009) & (udf['year'] <= 2022)]\n",
    "\n",
    "# Group and aggregate data to calculate sightings totals per state and year\n",
    "stateSightings = udf_filtered.groupby(['state', 'year']).size().reset_index(name='sightings')\n",
    "countrySightings = udf_filtered.groupby(['country', 'year']).size().reset_index(name='sightings')\n",
    "\n",
    "\n",
    "#pivots table and cleans column and\n",
    "def pivotTable(place, sightings):\n",
    "    pvPLACE = sightings.pivot(index=place, columns='year', values='sightings')\n",
    "    pvPLACE.reset_index(inplace=True)\n",
    "    pvPLACE.columns.name = None\n",
    "\n",
    "    # Fill any missing values (NaN) with zeros if necessary\n",
    "    pvPLACE.fillna(0, inplace=True)\n",
    "\n",
    "    pvPLACE.to_csv(f'{place}sightings2009-2022.csv', index=False)\n",
    "\n",
    "pivotTable('country', countrySightings)\n",
    "pivotTable('state', stateSightings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge both table\n",
    "state_data_path = \"statesightings2009-2022.csv\"\n",
    "country_data_path = \"countrysightings2009-2022.csv\"\n",
    "\n",
    "sdf = pd.read_csv(state_data_path)\n",
    "cdf = pd.read_csv(country_data_path)\n",
    "\n",
    "#Ensure clean merging\n",
    "cdf = cdf.rename(columns={'country': 'NAME'})\n",
    "sdf = sdf.rename(columns={'state': 'NAME'})\n",
    "\n",
    "USAdf = pd.concat([sdf, cdf], ignore_index=True)\n",
    "pdf = pd.read_csv(\"POP2009-2022.csv\")\n",
    "\n",
    "# Mapping of state abbreviations to full names\n",
    "state_abbreviations = {\n",
    "    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California',\n",
    "    'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia',\n",
    "    'HI': 'Hawaii', 'ID': 'Idaho', 'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas',\n",
    "    'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland', 'MA': 'Massachusetts',\n",
    "    'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi', 'MO': 'Missouri', 'MT': 'Montana',\n",
    "    'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico',\n",
    "    'NY': 'New York', 'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont',\n",
    "    'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming', 'USA': 'United States'\n",
    "}\n",
    "\n",
    "\n",
    "# Clean and transform the 'state' column\n",
    "USAdf['NAME'] = USAdf['NAME'].str.upper().str.strip().map(state_abbreviations)\n",
    "sdf.dropna(subset=['NAME'], inplace=True)  \n",
    "\n",
    "# List of American state names\n",
    "american_states = set(state_abbreviations.values())\n",
    "\n",
    "# Filter the DataFrame to include only American states\n",
    "USAdf = USAdf[USAdf['NAME'].isin(american_states)]\n",
    "USAdf = USAdf.groupby('NAME', as_index=False).sum()\n",
    "pdf = pdf.groupby('NAME', as_index=False).sum()\n",
    "\n",
    "\n",
    "USAdf.to_csv('USAsightings2009-2022.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the 'NAME' column as the index for both DataFrames\n",
    "pdf.set_index('NAME', inplace=True)\n",
    "USAdf.set_index('NAME', inplace=True)\n",
    "\n",
    "# Perform the operation df1 / df2 * 100000\n",
    "SCALEDdf = ((USAdf / pdf) * 1000000).round(0)\n",
    "\n",
    "SCALEDdf.dropna(how='all', inplace=True)\n",
    "SCALEDdf.to_csv('SCALEDsightings2009-2022.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject",
   "language": "python",
   "name": "myproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
