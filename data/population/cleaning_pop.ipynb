{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53 entries, 0 to 52\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   NAME              53 non-null     object\n",
      " 1   POPESTIMATE2009   53 non-null     int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 980.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "pop2009 = pd.read_csv(\"POP2009.csv\")\n",
    "pop2009.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['name', 'popestimate2009'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\emofr\\OneDrive\\Desktop\\summer 2023\\personal projects\\physics simulations\\UFO\\data\\population\\cleaning_pop.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/emofr/OneDrive/Desktop/summer%202023/personal%20projects/physics%20simulations/UFO/data/population/cleaning_pop.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m columns_to_keep1 \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpopestimate2009\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/emofr/OneDrive/Desktop/summer%202023/personal%20projects/physics%20simulations/UFO/data/population/cleaning_pop.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pop2009 \u001b[39m=\u001b[39m pop2009[columns_to_keep1]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/emofr/OneDrive/Desktop/summer%202023/personal%20projects/physics%20simulations/UFO/data/population/cleaning_pop.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Define a dictionary to map old column names to new ones\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/emofr/OneDrive/Desktop/summer%202023/personal%20projects/physics%20simulations/UFO/data/population/cleaning_pop.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m column_renamed \u001b[39m=\u001b[39m {\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/emofr/OneDrive/Desktop/summer%202023/personal%20projects/physics%20simulations/UFO/data/population/cleaning_pop.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mNAME\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/emofr/OneDrive/Desktop/summer%202023/personal%20projects/physics%20simulations/UFO/data/population/cleaning_pop.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPOPESTIMATE2009 \u001b[39m\u001b[39m'\u001b[39m : \u001b[39m'\u001b[39m\u001b[39mpopestimate2009\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/emofr/OneDrive/Desktop/summer%202023/personal%20projects/physics%20simulations/UFO/data/population/cleaning_pop.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m }\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5936\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5937\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 5938\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m   5941\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['name', 'popestimate2009'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "columns_to_keep1 = [\"name\", \"popestimate2009\"]\n",
    "pop2009 = pop2009[columns_to_keep1]\n",
    "\n",
    "# Define a dictionary to map old column names to new ones\n",
    "column_renamed = {\n",
    "    'NAME': 'name',\n",
    "    'POPESTIMATE2009 ' : 'popestimate2009',\n",
    "}\n",
    "\n",
    "# Rename the columns using the mapping\n",
    "pop2009.rename(columns=column_renamed, inplace=True)\n",
    "\n",
    "# Save the DataFrame with the new column names to a new CSV file\n",
    "pop2009.to_csv('POP2009.csv', index=False)\n",
    "\n",
    "pop2009.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57 entries, 0 to 56\n",
      "Data columns (total 19 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   SUMLEV             57 non-null     int64 \n",
      " 1   REGION             57 non-null     object\n",
      " 2   DIVISION           57 non-null     object\n",
      " 3   STATE              57 non-null     int64 \n",
      " 4   NAME               57 non-null     object\n",
      " 5   CENSUS2010POP      57 non-null     int64 \n",
      " 6   ESTIMATESBASE2010  57 non-null     int64 \n",
      " 7   POPESTIMATE2010    57 non-null     int64 \n",
      " 8   POPESTIMATE2011    57 non-null     int64 \n",
      " 9   POPESTIMATE2012    57 non-null     int64 \n",
      " 10  POPESTIMATE2013    57 non-null     int64 \n",
      " 11  POPESTIMATE2014    57 non-null     int64 \n",
      " 12  POPESTIMATE2015    57 non-null     int64 \n",
      " 13  POPESTIMATE2016    57 non-null     int64 \n",
      " 14  POPESTIMATE2017    57 non-null     int64 \n",
      " 15  POPESTIMATE2018    57 non-null     int64 \n",
      " 16  POPESTIMATE2019    57 non-null     int64 \n",
      " 17  POPESTIMATE042020  57 non-null     int64 \n",
      " 18  POPESTIMATE2020    57 non-null     int64 \n",
      "dtypes: int64(16), object(3)\n",
      "memory usage: 8.6+ KB\n"
     ]
    }
   ],
   "source": [
    "pop2020 = pd.read_csv(\"POP2010-2020.csv\")\n",
    "pop2020.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57 entries, 0 to 56\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   NAME             57 non-null     object\n",
      " 1   POPESTIMATE2010  57 non-null     int64 \n",
      " 2   POPESTIMATE2011  57 non-null     int64 \n",
      " 3   POPESTIMATE2012  57 non-null     int64 \n",
      " 4   POPESTIMATE2013  57 non-null     int64 \n",
      " 5   POPESTIMATE2014  57 non-null     int64 \n",
      " 6   POPESTIMATE2015  57 non-null     int64 \n",
      " 7   POPESTIMATE2016  57 non-null     int64 \n",
      " 8   POPESTIMATE2017  57 non-null     int64 \n",
      " 9   POPESTIMATE2018  57 non-null     int64 \n",
      " 10  POPESTIMATE2019  57 non-null     int64 \n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 5.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Assuming nuforc is a Pandas DataFrame\n",
    "columns_to_delete = [\"SUMLEV\", \"REGION\", \"DIVISION\", \"STATE\", \"CENSUS2010POP\", \"ESTIMATESBASE2010\", \"POPESTIMATE042020\", \"POPESTIMATE2020\" ]\n",
    "pop2020 = pop2020.drop(columns=columns_to_delete)\n",
    "pop2020.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 66 entries, 0 to 65\n",
      "Data columns (total 45 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   SUMLEV                 66 non-null     int64  \n",
      " 1   REGION                 66 non-null     object \n",
      " 2   DIVISION               66 non-null     object \n",
      " 3   STATE                  66 non-null     int64  \n",
      " 4   NAME                   66 non-null     object \n",
      " 5   ESTIMATESBASE2020      66 non-null     int64  \n",
      " 6   POPESTIMATE2020        66 non-null     int64  \n",
      " 7   POPESTIMATE2021        66 non-null     int64  \n",
      " 8   POPESTIMATE2022        66 non-null     int64  \n",
      " 9   NPOPCHG_2020           66 non-null     int64  \n",
      " 10  NPOPCHG_2021           66 non-null     int64  \n",
      " 11  NPOPCHG_2022           66 non-null     int64  \n",
      " 12  BIRTHS2020             66 non-null     int64  \n",
      " 13  BIRTHS2021             66 non-null     int64  \n",
      " 14  BIRTHS2022             66 non-null     int64  \n",
      " 15  DEATHS2020             66 non-null     int64  \n",
      " 16  DEATHS2021             66 non-null     int64  \n",
      " 17  DEATHS2022             66 non-null     int64  \n",
      " 18  NATURALCHG2020         66 non-null     int64  \n",
      " 19  NATURALCHG2021         66 non-null     int64  \n",
      " 20  NATURALCHG2022         66 non-null     int64  \n",
      " 21  INTERNATIONALMIG2020   66 non-null     int64  \n",
      " 22  INTERNATIONALMIG2021   66 non-null     int64  \n",
      " 23  INTERNATIONALMIG2022   66 non-null     int64  \n",
      " 24  DOMESTICMIG2020        66 non-null     int64  \n",
      " 25  DOMESTICMIG2021        66 non-null     int64  \n",
      " 26  DOMESTICMIG2022        66 non-null     int64  \n",
      " 27  NETMIG2020             66 non-null     int64  \n",
      " 28  NETMIG2021             66 non-null     int64  \n",
      " 29  NETMIG2022             66 non-null     int64  \n",
      " 30  RESIDUAL2020           66 non-null     int64  \n",
      " 31  RESIDUAL2021           66 non-null     int64  \n",
      " 32  RESIDUAL2022           66 non-null     int64  \n",
      " 33  RBIRTH2021             66 non-null     float64\n",
      " 34  RBIRTH2022             66 non-null     float64\n",
      " 35  RDEATH2021             66 non-null     float64\n",
      " 36  RDEATH2022             66 non-null     float64\n",
      " 37  RNATURALCHG2021        66 non-null     float64\n",
      " 38  RNATURALCHG2022        66 non-null     float64\n",
      " 39  RINTERNATIONALMIG2021  66 non-null     float64\n",
      " 40  RINTERNATIONALMIG2022  66 non-null     float64\n",
      " 41  RDOMESTICMIG2021       66 non-null     float64\n",
      " 42  RDOMESTICMIG2022       66 non-null     float64\n",
      " 43  RNETMIG2021            66 non-null     float64\n",
      " 44  RNETMIG2022            66 non-null     float64\n",
      "dtypes: float64(12), int64(30), object(3)\n",
      "memory usage: 23.3+ KB\n"
     ]
    }
   ],
   "source": [
    "pop2022 = pd.read_csv(\"POP2020-2022.csv\")\n",
    "pop2022.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 66 entries, 0 to 65\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   NAME             66 non-null     object\n",
      " 1   POPESTIMATE2020  66 non-null     int64 \n",
      " 2   POPESTIMATE2021  66 non-null     int64 \n",
      " 3   POPESTIMATE2022  66 non-null     int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 2.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Too many columns to delete, choosing a function that keeps certain columns instead\n",
    "columns_to_keep2 = [\"NAME\", \"POPESTIMATE2020\", \"POPESTIMATE2021\", \"POPESTIMATE2022\"]\n",
    "pop2022 = pop2022[columns_to_keep2]\n",
    "pop2022.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   NAME              52 non-null     object\n",
      " 1   POPESTIMATE2009   52 non-null     int64 \n",
      " 2   POPESTIMATE2010   52 non-null     int64 \n",
      " 3   POPESTIMATE2011   52 non-null     int64 \n",
      " 4   POPESTIMATE2012   52 non-null     int64 \n",
      " 5   POPESTIMATE2013   52 non-null     int64 \n",
      " 6   POPESTIMATE2014   52 non-null     int64 \n",
      " 7   POPESTIMATE2015   52 non-null     int64 \n",
      " 8   POPESTIMATE2016   52 non-null     int64 \n",
      " 9   POPESTIMATE2017   52 non-null     int64 \n",
      " 10  POPESTIMATE2018   52 non-null     int64 \n",
      " 11  POPESTIMATE2019   52 non-null     int64 \n",
      " 12  POPESTIMATE2020   52 non-null     int64 \n",
      " 13  POPESTIMATE2021   52 non-null     int64 \n",
      " 14  POPESTIMATE2022   52 non-null     int64 \n",
      "dtypes: int64(14), object(1)\n",
      "memory usage: 6.2+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_pop = pd.merge(pop2009, pop2020, on=\"NAME\")\n",
    "merged_pop = pd.merge(merged_pop, pop2022, on=\"NAME\")\n",
    "\n",
    "merged_pop.to_csv('POP2009-2022.csv', index=False)\n",
    "\n",
    "merged_pop.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a CVS file with columns containing NAME (of state), UFO sightings(2009-2022)\n",
    "ufo_data_path = \"../nuforc_reports.csv\"\n",
    "population_data_path = \"../population/POP2009-2022.csv\"\n",
    "\n",
    "udf = pd.read_csv(ufo_data_path)\n",
    "popdf = pd.read_csv(population_data_path)\n",
    "\n",
    "#Filter rows where the \"country\" column is equal to \"USA\" and keep only necessary coloumns\n",
    "udf = udf[udf['country'] == 'USA']\n",
    "udf = udf[[\"state\", \"country\", \"date\"]]\n",
    "\n",
    "# Convert the \"date_time\" column to datetime and extract year\n",
    "udf['date'] = pd.to_datetime(udf['date'])\n",
    "udf['year'] = udf['date'].dt.year\n",
    "\n",
    "# Filter the DataFrame to include only the years between 2000 and 2010\n",
    "udf_filtered = udf[ (udf['year'] >= 2009) & (udf['year'] <= 2022)]\n",
    "\n",
    "# Group and aggregate data to calculate sightings totals per state and year\n",
    "stateSightings = udf_filtered.groupby(['state', 'year']).size().reset_index(name='sightings')\n",
    "countrySightings = udf_filtered.groupby(['country', 'year']).size().reset_index(name='sightings')\n",
    "\n",
    "\n",
    "#pivots table and cleans column and index\n",
    "def pivotTable(place, sightings):\n",
    "    pvPLACE = sightings.pivot(index=place, columns='year', values='sightings')\n",
    "    pvPLACE.reset_index(inplace=True)\n",
    "    pvPLACE.columns.name = None\n",
    "\n",
    "    # Fill any missing values (NaN) with zeros if necessary\n",
    "    pvPLACE.fillna(0, inplace=True)\n",
    "\n",
    "    pvPLACE.to_csv(f'{place}sightings2009-2022.csv', index=False)\n",
    "\n",
    "pivotTable('country', countrySightings)\n",
    "pivotTable('state', stateSightings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'state_counts.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\emofr\\OneDrive\\Desktop\\summer 2023\\personal projects\\physics simulations\\UFO\\data\\population\\cleaning_pop.ipynb Cell 11\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/emofr/OneDrive/Desktop/summer%202023/personal%20projects/physics%20simulations/UFO/data/population/cleaning_pop.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m ufo_data_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../data/nuforc_reports.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/emofr/OneDrive/Desktop/summer%202023/personal%20projects/physics%20simulations/UFO/data/population/cleaning_pop.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m population_data_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../data/population/POP2009-2022.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/emofr/OneDrive/Desktop/summer%202023/personal%20projects/physics%20simulations/UFO/data/population/cleaning_pop.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(data_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/emofr/OneDrive/Desktop/summer%202023/personal%20projects/physics%20simulations/UFO/data/population/cleaning_pop.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m udf \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(ufo_data_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/emofr/OneDrive/Desktop/summer%202023/personal%20projects/physics%20simulations/UFO/data/population/cleaning_pop.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m popdf \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(population_data_path)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'state_counts.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path = \"state_counts.csv\"\n",
    "ufo_data_path = \"../data/nuforc_reports.csv\"\n",
    "population_data_path = \"../data/population/POP2009-2022.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "udf = pd.read_csv(ufo_data_path)\n",
    "popdf = pd.read_csv(population_data_path)\n",
    "\n",
    "#Remove unnesecary columns\n",
    "udf = udf.drop(columns=[\"summary\", \"country\", \"date_time\", \"shape\", \"duration\"])\n",
    "\n",
    "# Aggregate data\n",
    "\n",
    "state_counts = udf['state'].value_counts()\n",
    "city_counts = udf['city'].value_counts()\n",
    "\n",
    "\n",
    "state_counts_df = pd.DataFrame({'state': state_counts.index, \n",
    "                                'stateCount': state_counts.values, \n",
    "                                'city': city_counts.index,\n",
    "                                'cityCount' : city_counts.values,\n",
    "                                'latitude':udf['city_latitude'], \n",
    "                                'longtitude': udf['city_longtitude']})\n",
    "\n",
    "state_counts_file = 'counts.csv'\n",
    "state_counts_df.to_csv(state_counts_file, index=False)\n",
    "\n",
    "\n",
    "\n",
    "# Mapping of state abbreviations to full names\n",
    "state_abbreviations = {\n",
    "    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California',\n",
    "    'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia',\n",
    "    'HI': 'Hawaii', 'ID': 'Idaho', 'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas',\n",
    "    'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland', 'MA': 'Massachusetts',\n",
    "    'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi', 'MO': 'Missouri', 'MT': 'Montana',\n",
    "    'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico',\n",
    "    'NY': 'New York', 'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont',\n",
    "    'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "\n",
    "# Clean and transform the 'state' column\n",
    "df['state'] = df['state'].str.upper().str.strip().map(state_abbreviations)\n",
    "df.dropna(subset=['state'], inplace=True)  # Drop rows with NaN values\n",
    "\n",
    "# List of American state names\n",
    "american_states = set(state_abbreviations.values())\n",
    "\n",
    "# Filter the DataFrame to include only American states\n",
    "df = df[df['state'].isin(american_states)]\n",
    "\n",
    "# Group by 'state' and sum the 'count' values\n",
    "df = df.groupby('state', as_index=False)['count'].sum()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myproject",
   "language": "python",
   "name": "myproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
